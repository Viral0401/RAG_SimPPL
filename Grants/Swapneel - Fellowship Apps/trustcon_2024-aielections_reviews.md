## Proposal

Title
2024 Elections and AI Case Studies: Beware the six-fingered man
Authors
Abstract
We’re about halfway through the Year of Elections, with 83 elections expected across 78 countries by the end of 2024. How has AI impacted elections so far this year, and what can we expect from those to come? This panel will:

Share case studies from 3 - 4 elections, with a clear-eyed look at threats, mitigation efforts (if any), and actual harms in each case. Cases will be selected from different regions and political systems. 
Unpack lessons learned, both positive and negative, in terms of how tech platforms handled them, and provide concrete guidance for future scenarios.
Discuss opportunities to take preventative and post-hoc measures to combat information interference.
Topic Areas
Investigations & Intelligence
Community contribution
We hope this will:

Benefit T&S workers at platforms involving content, across problem areas of election integrity, misinformation, transparency, inauthentic and deceptive behavior, info ops/coordinated harm, offline harm. This can provide insight to help these teams adjust election integrity plans and operations.
Benefit T&S people involved in responsible & ethical AI, especially generative AI, understand the demonstrated and emerging risks their systems and processes may pose to online information integrity, voter participation, and potentially offline harm.
Contribute to the public discussion, helping distinguish top threats from broad speculation.
Intended audience
Mid-level (or some experience in T&S)
Press
Yes, press can attend.
Space or platform
Social media
Primary theme
Emerging trends
Secondary theme
Scaling T&S
Additional information
Below are the core questions we're planning. Note that this supplements rather than replaces the Abstract. 

What are the trends & patterns in how generative AI has been used in elections around the world so far this year (and before 2024)?
What were the outcomes of those elections?
What do we know about the AI systems used to generate the content?
How was the AI-generated content distributed?
As problematic as video deepfakes are, they've also in effect become shiny objects. What issues aren't getting enough attention, by platforms and in public discourse? (E.g., AI-powered chatbots)
In countries where AI was used adversarially in elections, what countermeasures, if any, were attempted? What do we know about their efficacy?
Much of the public discussion, as well as emerging legislation in the U.S., focuses on deepfakes that directly target politicians. What other types of deepfake targeting and tactics are we seeing in the U.S. and elsewhere? E.g., fake election officials, false information about voting logistics. What should we be anticipating? (E.g., 11th hour incendiary videos of social media platforms, decide to facilitate civil unrest in targeted areas)
How have AI-driven disinformation campaigns, deployed by regimes that mix democratic and authoritarian tactics and are notorious for suppressing dissent and propagating misinformation, affected election results?
Did this advanced manipulation prompt voters to seek out more authoritative and reliable sources for information, or were they inclined to disregard the altered content?
Is there evidence to suggest that exposure to this AI-generated disinformation affected voter turnout or influenced their decisions at the polls?
As of this writing, here are case studies we have in we have in mind:

Cases of GenAI used adversarially:
Taiwan election, Jan. ‘24: Generative AI was used in what researchers believe to be an info operation run by the Chinese Communist Party. There were videos on IG and YT with AI-generated newscaster avatars, who read from a fake book alleging scandalous things about the then-president Tsai Ing-Wen, whose party is less sympathetic to China. Tsai’s party's candidate, William Lai, won the presidential race.
Turkyie election March ’24: Early reports suggest that the AKP political party is producing deepfake videos for campaign ads in Turkyie’s legislative election. In early March, a deepfake of incumbent mayor Imamoglu falsely praising President Erdogan for his achievements in Istanbul was circulating on social media. This follows the same trend from 2023, where the AKP party posted a photo of an opposition leader with members of a terrorist organization (PKK), with President Erdogan noting that it was fake, but still chose to use it.
Cases of GenAI used to connect with voters:
Indonesia election, Feb. ‘24: Prabowo Subianto's campaign used AI-generated cartoon likenesses of him as a "cuddly grandpa" to soften the alleged human rights abuser and former general’s image. He is now president-elect.
Pakistan election, Feb. ‘24: Jailed ex-prime minister Imran Khan's party used AI to create videos of him giving campaign speeches. They also released an AI-generated video of him giving a victory speech before results were conclusive and when the opposition party leader had also declared victory. Though Khan’s party was banned from running for the National Assembly, members ran as independents and pulled off a surprise win.
South Korea election, March ‘22 and April '24: We're going to examine the continuum of AI use across two elections, with the 2024 election in the adversarial category. In March '22, then-presidential candidate Yoon Suk-yeol’s campaign released a series of AI-generated videos of a more approachable and engaging version of Yoon. This Yoon discussed topics meant to appeal to younger voters, in a highly meme-able and humorous tone, to soften his image in real-life as a stern prosecutor. Yoon won the election.

As South Korea approaches its parliamentary next month, deepfakes are being disseminated on social media platforms, targeting opposition candidates. South Korea's National Election Commission reported in February that 129 deepfakes, all in violation of campaign laws, had been identified over a 19 day period, 
Re the panel title: historically, deepfake image generators struggled with hands, often producing an extra finger or two. Inigo Montoya would not have approved.

Submission Format
Full Panel (3-4 panelists and moderator)

Submission Date
2nd Feb 2024, 10:29pm PST

Decision
Full Panel

## Reviews

First, thank you for submitting this proposal and for the opportunity to review it! I appreciate that your proposal combines case studies with recommendations and opportunities to improve for other regional elections. Though I know the specific elections being covered likely won't be decided upon until closer to the event, my hope is that diverse regions and types of elections will be covered.

Thank you for this submission! This is a very clear and detailed proposal, which I appreciated, and the topic will be of interest to many at TrustCon. I liked the inclusion of concrete examples -- I find that this is often missing from conversations about generative AI and elections.

Thank you for submitting this proposal! I found your proposal to be very relevant to TrustCon, especially with the upcoming US elections and the potential dangers of AI. For the future, my advice is to either convert this into a presentation with slides so our audience can better understand the case studies and lessons learned, instead of a full panel. When submitting a full panel, we highly suggest you include the complete list of questions which will be discussed and asked by the moderator during the panel.

Your proposal covers a topic that has seen widespread discussion in the trust and safety field/in public discourse; incorporating unique insights or a fresh perspective could significantly enhance its originality. As such, please try to revise so that the case studies you present add unique cases to the field. We've heard a lot about general risks of AI and their intersection with election work. There's a strong case for your proposal as the panel is composed of researchers who can definitely add new perspectives.
